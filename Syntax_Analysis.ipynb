{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9821aa94-43cb-48d1-b17d-99586a48ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import BertTokenizer\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a063d5a4-304d-4ac5-abd3-0e6afd19d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = None\n",
    "with open(\"dev_parse.pickle\", 'rb') as file:\n",
    "    examples = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2e3254-9e27-4567-9b35-de616e07a69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for example in examples:\n",
    "    for label in example['labels']:\n",
    "        counts[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15aeb5e7-b793-456e-ab33-e19c015d491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_example = None\n",
    "for i in range(len(examples)):\n",
    "    try:\n",
    "        assert examples[i][\"attention_map\"].shape[-1]-2 == len(examples[i]['words'])\n",
    "    except:\n",
    "        faulty_example = examples[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63793c7e-5fde-492d-a43d-20bca0042fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert faulty_example is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e63219-d269-47dc-9428-4b2c36bd2311",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LAYERS,NUM_HEADS,_,_ = examples[0]['attention_map'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c2833d-e297-4b60-8ffd-ba7efd62c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(example,layer,head,mode = \"normal\"):\n",
    "    '''This function takes in an example (examples[i]) and uses the attention map of that example to \n",
    "    predict the head of each word in the example. The output is of same length as of example['words'] -2. -2 because predictor doesn't predict\n",
    "    heads for [CLS] and [SEP] token\n",
    "    \n",
    "    layer -> layer in attention map to be used to predict\n",
    "    head -> attention head in the the layer to predict heads\n",
    "    mode -> if mode is 'normal' the head of word i is deemed to be the word j if j is the word `to` which i pays most attention i.e argmax(attn[layer][head][i]). In other words dependent is\n",
    "            paying the most attention to it's head.\n",
    "            if mode is 'transpose' the head of word i deemed to be the word j if j is the word `from` which i gets the most attention i.e argmax(attn[layer][head][:][i]) or argmax(attn.T[layer][head][i]).\n",
    "            In other words, head is paying the most attention to dependent.\n",
    "    '''\n",
    "    \n",
    "    attn = example['attention_map'][layer][head]\n",
    "    \n",
    "    if mode == \"transpose\": attn = attn.T\n",
    "    attn[range(attn.shape[0]), range(attn.shape[0])] = 0 #ignoring the attention to self by setting diagonal elements to 0.\n",
    "    \n",
    "    attn = attn[1:-1, 1:-1] #ignoring attention from and to [CLS] and [SEP] token\n",
    "    return np.argmax(attn, axis = -1) + 1 #because 0 prediction would mean the head is ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9dbd20b-9e80-4ae6-a062-45a5b70dca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictor(examples, predictor):\n",
    "    '''Takes in a bunch of examples and calculates the head prediction accuracy of each word in each examples and averages them up\n",
    "    Additionally, also calculates the accuracy of each type of relation between words'''\n",
    "    \n",
    "    num_correct, num_incorrect = Counter(), Counter()\n",
    "    all_labels = []\n",
    "    for example in examples:\n",
    "        words = example['words']\n",
    "        labels = example['labels']\n",
    "        heads = example['heads']\n",
    "         \n",
    "        predictions = predictor(example)\n",
    "        \n",
    "        assert len(predictions) == len(labels)\n",
    "        \n",
    "        for i, (prediction, label, head) in enumerate(zip(predictions, labels, heads)):\n",
    "            if label != 'root' and label != 'punct':\n",
    "                all_labels.append(label)\n",
    "                if prediction == head:\n",
    "                    num_correct[label] += 1\n",
    "                    num_correct['all'] += 1\n",
    "\n",
    "                else:\n",
    "                    num_incorrect[label] += 1\n",
    "                    num_incorrect['all'] += 1 \n",
    "                \n",
    "    return {label: num_correct[label]/ float(num_correct[label] + num_incorrect[label]) for label in all_labels}\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9d3cae-f1e2-4847-b49c-4db7da8d3a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(dataset, mode = \"normal\"):\n",
    "    scores = defaultdict(dict)\n",
    "    global NUM_LAYERS, NUM_HEADS\n",
    "    for layer in range(NUM_LAYERS):\n",
    "        for head in range(NUM_HEADS):\n",
    "            scores[layer][head] = evaluate_predictor(dataset, predictor = partial(predict, layer = layer, head = head, mode = mode))\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c753ce1a-8cbe-40a7-8b76-a2c25e463043",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dictionary = {\n",
    "    \"dep->head\": get_scores(examples, mode = \"normal\"),\n",
    "    \"head->dep\": get_scores(examples, mode = \"transpose\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb8421c6-7e6e-44a7-a9c5-f4e32621bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_stats(scores_dictionary):\n",
    "    global counts\n",
    "    stats = namedtuple('Stats', field_names = ['accuracy', 'layer', 'head', 'mode'])\n",
    "    relation_stats = {label:stats(0,0,0,None) for label in scores_dictionary['dep->head'][0][0].keys()}\n",
    "    \n",
    "    for mode,scores in scores_dictionary.items():\n",
    "        for layer in range(NUM_LAYERS):\n",
    "            for head in range(NUM_HEADS):\n",
    "                for label in relation_stats.keys():\n",
    "                    if scores[layer][head][label] >= relation_stats[label].accuracy:\n",
    "                        relation_stats[label] = stats(scores[layer][head][label], layer, head, mode)\n",
    "                        \n",
    "    return relation_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be82f3e1-8691-425e-b4b8-5ee9dd390eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = get_relation_stats(scores_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dbc5454c-f52f-4840-86bf-5b727ddbaece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amod': Stats(accuracy=0.7583465818759937, layer=5, head=4, mode='dep->head'),\n",
       " 'nsubj': Stats(accuracy=0.5866906474820144, layer=8, head=9, mode='dep->head'),\n",
       " 'case': Stats(accuracy=0.757248981548047, layer=6, head=4, mode='dep->head'),\n",
       " 'det': Stats(accuracy=0.9383829275623685, layer=6, head=4, mode='dep->head'),\n",
       " 'compound': Stats(accuracy=0.7232704402515723, layer=6, head=10, mode='dep->head'),\n",
       " 'nmod': Stats(accuracy=0.24612348463490274, layer=7, head=8, mode='dep->head'),\n",
       " 'cc': Stats(accuracy=0.47952047952047955, layer=6, head=5, mode='dep->head'),\n",
       " 'conj': Stats(accuracy=0.464746772591857, layer=11, head=11, mode='head->dep'),\n",
       " 'dobj': Stats(accuracy=0.8216249236408063, layer=5, head=7, mode='dep->head'),\n",
       " 'aux': Stats(accuracy=0.7387267904509284, layer=6, head=8, mode='dep->head'),\n",
       " 'acl:relcl': Stats(accuracy=0.3793103448275862, layer=8, head=6, mode='dep->head'),\n",
       " 'advmod': Stats(accuracy=0.5309423347398031, layer=5, head=6, mode='dep->head'),\n",
       " 'ccomp': Stats(accuracy=0.4109090909090909, layer=7, head=6, mode='dep->head'),\n",
       " 'xcomp': Stats(accuracy=0.6967741935483871, layer=5, head=2, mode='dep->head'),\n",
       " 'nmod:poss': Stats(accuracy=0.6614950634696756, layer=6, head=7, mode='dep->head'),\n",
       " 'appos': Stats(accuracy=0.29347826086956524, layer=5, head=5, mode='head->dep'),\n",
       " 'dep': Stats(accuracy=0.2728658536585366, layer=9, head=7, mode='head->dep'),\n",
       " 'mark': Stats(accuracy=0.7153846153846154, layer=6, head=8, mode='dep->head'),\n",
       " 'advcl': Stats(accuracy=0.2578740157480315, layer=6, head=11, mode='head->dep'),\n",
       " 'nsubjpass': Stats(accuracy=0.6284584980237155, layer=7, head=8, mode='dep->head'),\n",
       " 'neg': Stats(accuracy=0.7386934673366834, layer=4, head=5, mode='dep->head'),\n",
       " 'auxpass': Stats(accuracy=0.958041958041958, layer=5, head=6, mode='dep->head'),\n",
       " 'cop': Stats(accuracy=0.7780612244897959, layer=6, head=4, mode='dep->head'),\n",
       " 'nummod': Stats(accuracy=0.8473282442748091, layer=5, head=6, mode='dep->head'),\n",
       " 'acl': Stats(accuracy=0.4339622641509434, layer=6, head=5, mode='dep->head'),\n",
       " 'mwe': Stats(accuracy=0.9797979797979798, layer=6, head=9, mode='head->dep'),\n",
       " 'compound:prt': Stats(accuracy=0.9827586206896551, layer=6, head=2, mode='dep->head'),\n",
       " 'parataxis': Stats(accuracy=0.2542372881355932, layer=11, head=11, mode='dep->head'),\n",
       " 'nmod:tmod': Stats(accuracy=0.42448979591836733, layer=6, head=5, mode='dep->head'),\n",
       " 'nmod:npmod': Stats(accuracy=0.5658914728682171, layer=4, head=2, mode='dep->head'),\n",
       " 'csubj': Stats(accuracy=0.4666666666666667, layer=7, head=3, mode='dep->head'),\n",
       " 'discourse': Stats(accuracy=0.42857142857142855, layer=10, head=2, mode='head->dep'),\n",
       " 'iobj': Stats(accuracy=0.8888888888888888, layer=5, head=7, mode='dep->head'),\n",
       " 'cc:preconj': Stats(accuracy=0.45454545454545453, layer=5, head=1, mode='head->dep'),\n",
       " 'expl': Stats(accuracy=0.90625, layer=6, head=1, mode='head->dep'),\n",
       " 'det:predet': Stats(accuracy=0.9285714285714286, layer=6, head=4, mode='dep->head'),\n",
       " 'csubjpass': Stats(accuracy=1.0, layer=9, head=10, mode='head->dep')}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62f983-5d10-4c39-9d42-3ad75796acd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
